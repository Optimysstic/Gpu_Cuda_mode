{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTL7WgEsUpwp",
        "outputId": "b8423bcb-b130-4f69-aac4-d6b31fec4173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  4,  9, 16, 25])\n",
            "=============\n",
            "Profiling torch.square\n",
            "=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e915040dd287>:38: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
            "  with torch.autograd.profiler.profile(use_cuda = True) as prof:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                aten::mul        99.98%     197.639ms        99.98%     197.639ms     197.639ms     197.705ms       100.00%     197.705ms     197.705ms             1  \n",
            "          cudaEventRecord         0.01%      22.731us         0.01%      22.731us      11.366us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "    cudaDeviceSynchronize         0.01%      18.794us         0.01%      18.794us      18.794us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 197.681ms\n",
            "Self CUDA time total: 197.705ms\n",
            "\n",
            "=============\n",
            "Profiling squared_tensor * squared_tensor\n",
            "=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e915040dd287>:45: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
            "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                aten::mul        99.98%     214.587ms        99.98%     214.587ms     214.587ms     214.656ms       100.00%     214.656ms     214.656ms             1  \n",
            "          cudaEventRecord         0.01%      32.190us         0.01%      32.190us      16.095us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "    cudaDeviceSynchronize         0.01%      18.718us         0.01%      18.718us      18.718us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 214.638ms\n",
            "Self CUDA time total: 214.656ms\n",
            "\n",
            "=============\n",
            "Profiling squared_tensor ** 2\n",
            "=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e915040dd287>:54: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
            "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                aten::pow        99.97%     208.006ms        99.98%     208.021ms     208.021ms     208.067ms        99.99%     208.079ms     208.079ms             1  \n",
            "                 aten::to         0.00%       1.941us         0.00%       1.941us       1.941us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "        aten::result_type         0.00%       2.334us         0.00%       2.334us       2.334us       5.000us         0.00%       5.000us       5.000us             1  \n",
            "          cudaEventRecord         0.02%      37.147us         0.02%      37.147us       6.191us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "    cudaDeviceSynchronize         0.01%      21.467us         0.01%      21.467us      21.467us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 208.069ms\n",
            "Self CUDA time total: 208.079ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# element wise square\n",
        "import torch\n",
        "tensor = torch.tensor([1,2,3,4,5])\n",
        "squared_tensor = tensor ** 2\n",
        "# squared_tensor = torch.square(tensor)\n",
        "print(squared_tensor)\n",
        "\n",
        "def time_pytorch_function(func, input):\n",
        "  start = torch.cuda.Event(enable_timing = True)\n",
        "  end = torch.cuda.Event(enable_timing = True)\n",
        "\n",
        "  # warmup\n",
        "  for _ in range(5):\n",
        "    func(input)\n",
        "  start.record()\n",
        "  func(input)\n",
        "  end.record()\n",
        "  torch.cuda.synchronize()\n",
        "  return start.elapsed_time(end)\n",
        "\n",
        "b = torch.rand(10000, 10000)\n",
        "\n",
        "def square_2(squared_tensor):\n",
        "  return squared_tensor * squared_tensor\n",
        "\n",
        "def square_3(squared_tensor):\n",
        "  return squared_tensor ** 2\n",
        "\n",
        "time_pytorch_function(torch.square, b)\n",
        "time_pytorch_function(square_2, b)\n",
        "time_pytorch_function(square_3, b)\n",
        "\n",
        "print(\"=============\")\n",
        "print(\"Profiling torch.square\")\n",
        "print(\"=============\")\n",
        "\n",
        "# now profile each function using pytorch profiler\n",
        "with torch.autograd.profiler.profile(use_cuda = True) as prof:\n",
        "  square_2(b)\n",
        "print(prof.key_averages().table(sort_by = \"cuda_time_total\", row_limit = 10))\n",
        "print(\"=============\")\n",
        "print(\"Profiling squared_tensor * squared_tensor\")\n",
        "print(\"=============\")\n",
        "\n",
        "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "    square_2(b)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "\n",
        "print(\"=============\")\n",
        "print(\"Profiling squared_tensor ** 2\")\n",
        "print(\"=============\")\n",
        "\n",
        "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "    square_3(b)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}